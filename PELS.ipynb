{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c539a60d-4daf-482e-be9a-8c66f9a7692f",
   "metadata": {},
   "source": [
    "# PELS tutorrial hands on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c8928-233a-4535-8792-2834608441e2",
   "metadata": {},
   "source": [
    "## Let us understand the system\n",
    "\n",
    "* We query the system topology using LIKWID tool.\n",
    "* Note that only 1 NUMA domain (16 cores) of CPU is available.\n",
    "* Attached is also one A100 GPU.\n",
    "* Watch out for the available cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332686c9-5f4b-4899-8f09-59cb57e03a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!likwid-topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751e94b-5c95-49f4-a7d1-f3dc8bdba371",
   "metadata": {},
   "source": [
    "## CPU main memory bandwidth\n",
    "\n",
    "* Main memory bandwidth is the most important hardware characteristic relevant to SpMV like kernels.\n",
    "* Let us measure the bandwidth using LIKWID tool.\n",
    "* Note that bandwidth of only 1 NUMA domain (16 cores) is measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae5e2a-1b7d-44f4-b3f9-1481df7911e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!likwid-bench -t load_avx -w N:4GB:16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80131f-d9b4-48d2-ad69-238fdda54dc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let us set up our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57f9e1-5a48-4a8d-ba3b-013f37f330b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#On cluster we might not have internet to download packages\n",
    "#so we set path to pre-installed Python packages\n",
    "sys.path.insert(0, \"/home/hpc/unrz/unrz002h/installkit/lib/python3.9/site-packages\") \n",
    "\n",
    "import os\n",
    "os.environ[\"USE_RACE\"]=\"1\" #Compile RACE too\n",
    "os.environ[\"OMP_SCHEDULE\"]=\"static\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae552b1-be64-447c-b9a3-a66c36c46b35",
   "metadata": {},
   "source": [
    "## Have a look at our main CG routine\n",
    "* CG solver is implemented using the cg_solve function.\n",
    "* Notice the kernels used for implementing CG solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5b6c5-5c17-4110-9ea1-439e90e51654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kernels import *\n",
    "import numpy as np\n",
    "import numba\n",
    "import gc\n",
    "from numpy.linalg import norm\n",
    "from scipy.sparse import *\n",
    "from scipy.io import mmread\n",
    "from sellcs import sellcs_matrix\n",
    "from poly_op import *\n",
    "\n",
    "\n",
    "from matrix_generator import create_matrix\n",
    "\n",
    "def cg_solve(A, b, x0, tol, maxit, verbose=False, x_ex=None):\n",
    "    '''\n",
    "    x, tol, iter = cg_solve(A, b, x0, tol, maxit)\n",
    "    Where A is an spd scipy.sparse.csr_matrix, b and x0 are numpy.array's of size A.shpae[0],\n",
    "    tol is the convergence tolerance and maxit the maximum number of iterations.\n",
    "    '''\n",
    "    x = clone(b)\n",
    "    r = clone(b)\n",
    "    p = clone(b)\n",
    "    q = clone(b)\n",
    "\n",
    "    err_norms=[]\n",
    "    res_norms=[]\n",
    "    \n",
    "    if x_ex is not None:\n",
    "        print('PerfWarning: providing the exact solution x_ex results in additional operations to calculate and print the error norm.')\n",
    "        err = clone(b)\n",
    "\n",
    "    tol2 = tol*tol\n",
    "\n",
    "\n",
    "    axpby(1.0,x0,0.0,x)\n",
    "\n",
    "    #r = A*x\n",
    "    if hasattr(A, 'apply'):\n",
    "        A.apply(x, r)\n",
    "    else:\n",
    "        spmv(A, x, r)\n",
    "    #r = b - r\n",
    "    axpby(1.0, b, -1.0, r)\n",
    "    #p = r\n",
    "    axpby(1.0, r, 0.0, p)\n",
    "\n",
    "    # rho = <r, r>\n",
    "    rho = dot(r,r);\n",
    "    rho_old = 1.0\n",
    "    if verbose:\n",
    "        print('%d\\t%e'%(0, np.sqrt(rho)))\n",
    "\n",
    "\n",
    "    for iter in range(maxit+1):\n",
    "\n",
    "        # check stop criteria\n",
    "        if rho < tol2:\n",
    "            break;\n",
    "\n",
    "        # q = A*p\n",
    "        if hasattr(A, 'apply'):\n",
    "            A.apply(p, q)\n",
    "        else:\n",
    "            spmv(A, p, q)\n",
    "\n",
    "        pq = dot(p,q)\n",
    "        alpha = rho / pq\n",
    "        # x = x+alpha*p\n",
    "        axpby(alpha, p, 1.0, x)\n",
    "        # r = r - alpha*q\n",
    "        axpby(-alpha, q, 1.0, r)\n",
    "\n",
    "        rho_old = rho\n",
    "        rho = dot(r, r)\n",
    "\n",
    "        curr_res_norm=np.sqrt(rho)\n",
    "        res_norms.append(curr_res_norm)\n",
    "        if x_ex is not None:\n",
    "            if hasattr(A, 'unprec_sol'):\n",
    "                A.unprec_sol(x, err)\n",
    "            else:\n",
    "                axpby(1.0, x, 0.0, err)\n",
    "            axpby(-1.0, x_ex, 1.0, err)\n",
    "            curr_err_norm=np.sqrt(dot(err, err))\n",
    "            err_norms.append(curr_err_norm)    \n",
    "            if verbose:\n",
    "                print('%d\\t%e\\t%e'%(iter+1, curr_res_norm, curr_err_norm))\n",
    "        else:   \n",
    "            if verbose:\n",
    "                print('%d\\t%e'%(iter+1, curr_res_norm))\n",
    "\n",
    "        beta = rho / rho_old\n",
    "        # p = r+beta*p\n",
    "        axpby (1.0, r, beta, p)\n",
    "\n",
    "    iter_count = iter\n",
    "    final_residual = np.sqrt(rho)\n",
    "\n",
    "    return x, final_residual, iter_count, res_norms, err_norms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pcg(matrix, maxit, mat_fmt='CSR', poly_k=0, tol=1e-3, use_RACE=False, cache_size=60, rand_seed=1, print_perf=False):\n",
    "    ## **Note:** The Python garbage collector (gc)\n",
    "    ## can kill the performance of the C kernels\n",
    "    ## for some obscure reason (possibly a conflict\n",
    "    ## between Numba/LLVM and other compilers like GCC).\n",
    "    ## For the pure Python/numba/cuda kernels, this is not\n",
    "    ## the case, but if you are facing obvious performnace\n",
    "    ## problems with the C kernels, you may want to disalbe\n",
    "    ## garbage collection:\n",
    "    gc.disable()\n",
    "\n",
    "    if rand_seed is not None:\n",
    "        np.random.seed(rand_seed)\n",
    "\n",
    "    #if args.matfile != 'None':\n",
    "    #    if args.matgen!='None':\n",
    "    #        print('got both -matfile and -matgen, the latter will be ignored.')\n",
    "    #    if not args.matfile.endswith(('.mm','.mtx','.mm.gz','.mtx.gz')):\n",
    "    #        raise(ValueError('Expecting MatrixMarket file with extension .mm[.gz] or .mtx[.gz]'))\n",
    "    #    A = csr_matrix(mmread(args.matfile))\n",
    "    A = create_matrix(matrix)\n",
    "    N = A.shape[0]\n",
    "\n",
    "    x_ex=np.random.rand(N)\n",
    "\n",
    "    b=A*x_ex\n",
    "\n",
    "    x0 = np.zeros(N,dtype='float64')\n",
    "\n",
    "    print('norm of rhs: %e'%(norm(b)))\n",
    "    print('rel. residual of given solution: %e'%(norm(A*x_ex-b)/norm(b)))\n",
    "\n",
    "    sigma=1\n",
    "\n",
    "    A_csr = A # we may need it for creating the preconditioner\n",
    "              # in case the user wants a SELL-C-sigma matrix.\n",
    "\n",
    "    print(\"nnz = \", A.nnz, \"nrows =\", N, \"nnzr =\", A.nnz/N)\n",
    "    if 'SELL' in mat_fmt:\n",
    "        C_=int(mat_fmt.split('-')[1])\n",
    "        if C_ > 256:\n",
    "            print('C greater than 256. Setting to maximum possible value 256')\n",
    "            C_ = 256\n",
    "        sigma_=int(mat_fmt.split('-')[2])\n",
    "        print('Matrix format: SELL-%d-%d'%(C_,sigma_))\n",
    "        A = sellcs_matrix(A_csr=A_csr, C=C_, sigma=sigma_)\n",
    "        b = b[A.permute]\n",
    "        A_csr = A_csr[A.permute[:,None], A.permute]\n",
    "    else:\n",
    "        print('Matrix format: CSR')\n",
    "\n",
    "    if available_gpus()>0:\n",
    "        type = 'gpu'\n",
    "    else:\n",
    "        type = 'cpu'\n",
    "\n",
    "    print('Will run on '+type)\n",
    "    \n",
    "    numa=True\n",
    "    \n",
    "    if type=='gpu':\n",
    "        x0 = to_device(x0)\n",
    "        b  = to_device(b)\n",
    "        A  = to_device(A)\n",
    "        x_ex = to_device(x_ex)\n",
    "\n",
    "    #Just run all the kernels one time. Just for catching any errors\n",
    "    compile_all() \n",
    "\n",
    "    A_prec = A\n",
    "    b_prec = b\n",
    "\n",
    "    # we want to make sure what we measure during CG in total\n",
    "    # is consistent with the sum of the kernel calls and their\n",
    "    # runtime as predicted by the roofline model, so reset all\n",
    "    # counters and timers:\n",
    "    reset_counters()\n",
    "\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    t0_pre = perf_counter()\n",
    "    if poly_k>0:\n",
    "        # building preconditioners typically requires a certain format,\n",
    "        # in our case, the poly_op class uses scipy functions tril and triu,\n",
    "        # which are not implemented by the sellcs_matrix class.\n",
    "        print(\"calling poly_op \", poly_k)\n",
    "        A_prec = poly_op(A_csr, poly_k, use_RACE, cache_size)\n",
    "        if A_prec.mpkHandle != None:\n",
    "            b = b[A_prec.permute]\n",
    "            A_csr = A_csr[A_prec.permute[:,None], A_prec.permute]\n",
    "        if 'SELL' in mat_fmt:\n",
    "            # note: If A was originally sorted by row-length (sigma>1), use the same\n",
    "            # sorting for L and U to avoid intermittent permutation by setting sigma=1.\n",
    "            # There still seems to be some kind of bug, though, because the number of\n",
    "            # iterations will increase with poly_k>0 and sigma>1. Hence this warning.\n",
    "            C_=int(mat_fmt.split('-')[1])\n",
    "            sigma_=int(mat_fmt.split('-')[2])\n",
    "            A_prec.L = to_device(sellcs_matrix(A_csr=A_prec.L, C=C_, sigma=1))\n",
    "            A_prec.U = to_device(sellcs_matrix(A_csr=A_prec.U, C=C_, sigma=1))\n",
    "        b_prec = copy(b)\n",
    "        A_prec.prec_rhs(b, b_prec)\n",
    "\n",
    "    \n",
    "    #hw_string = type\n",
    "    #if type=='cpu':\n",
    "    #    hw_string+=' ('+str(numba.threading_layer())+', '+str(numba.get_num_threads())+' threads)'\n",
    "    #print('Hardware: '+hw_string)\n",
    "    \n",
    "    printerr=True\n",
    "    x_ex_in = None\n",
    "    if printerr:\n",
    "        x_ex_in = x_ex  \n",
    "        if poly_k>0:\n",
    "            if A_prec.mpkHandle != None:\n",
    "                x_ex_in = x_ex_in[A_prec.permute]\n",
    "\n",
    "    t1_pre = perf_counter()\n",
    "\n",
    "    t0_soln = perf_counter()\n",
    "    x_prec, relres, iter, res_norms, err_norms = cg_solve(A_prec,b_prec,x0,tol,maxit, x_ex=x_ex_in)\n",
    "\n",
    "    t1_soln = perf_counter()\n",
    "\n",
    "    if poly_k>0:\n",
    "        x = clone(x_prec)\n",
    "        A_prec.unprec_sol(x_prec, x)\n",
    "    else:\n",
    "        x = x_prec\n",
    "\n",
    "    t1 = perf_counter()\n",
    "    t_pre = t1_pre-t0_pre\n",
    "    t_soln = t1_soln-t0_soln\n",
    "    t_CG = t1-t0\n",
    "    gc.enable()\n",
    "\n",
    "    x = to_host(x)\n",
    "\n",
    "    rel_err_norms=err_norms/norm(x_ex)\n",
    "    rel_res_norms=res_norms/norm(b)\n",
    "    \n",
    "    print('number of CG iterations: %d'%(iter))\n",
    "    res = np.empty_like(x)\n",
    "    spmv(A_csr,x,res)\n",
    "    res=b-res\n",
    "    print('relative residual of computed solution: %e'%(norm(res)/norm(b)))\n",
    "\n",
    "    if 'SELL' in mat_fmt and sigma>1:\n",
    "        x = x[A.unpermute]\n",
    "\n",
    "    if poly_k>0:\n",
    "        if A_prec.mpkHandle != None:\n",
    "            x = x[A_prec.unpermute]\n",
    "\n",
    "    print('relative error of computed solution: %e'%(norm(x-x_ex)/norm(x_ex)))\n",
    "\n",
    "    if print_perf:\n",
    "        perf_report(type)\n",
    "    if poly_k>0:\n",
    "        print('Total time for constructing precon: %g seconds.'%(t_pre))\n",
    "        print('Total time for solving: %g seconds.'%(t_soln))\n",
    "    print('Total time for CG: %g seconds.'%(t_CG))\n",
    "    \n",
    "    return rel_res_norms, rel_err_norms, iter, t_pre, t_soln, t_CG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4ad05-e5d2-4f7d-b7fa-13bfa77cf789",
   "metadata": {},
   "source": [
    "## Let us run a simple example on CPU\n",
    "* The matrix used is a simple 2D Laplacian of dimension 2000x2000.\n",
    "* CG solver is run for 1000 iterations.\n",
    "* At the end of the solver performance of each kernel used in CG is reported.\n",
    "    * What is the most costly component?\n",
    "    * Does the performance of SpMV match with the measured bandwidth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19312b3d-41c5-4e2f-b069-46cbd077f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"USE_CPU\"]=\"True\"\n",
    "rel_res_in_CG, rel_err, iter, t_pre, t_soln, t_CG = pcg('Laplace200x200x200', 50, print_perf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504d364-cc14-4af5-96a0-0b23388cd0f9",
   "metadata": {},
   "source": [
    "## Now let us run on GPU\n",
    "* Notice that CG solver is much faster.\n",
    "* Is it the best we can do on this GPU? (Hint: Bandwidth of one A100 is roughly around 1.5 TB/s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219ec3f-d5f0-43fd-a0c5-d79f5f9d4e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"USE_CPU\"]=\"False\"\n",
    "rel_res_in_CG, rel_err, iter, t_pre, t_soln, t_CG = pcg('Laplace200x200x200', 200,  print_perf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba57e8-45c1-4949-86c5-26b0bedf8427",
   "metadata": {},
   "source": [
    "## Matrix formats\n",
    "* See what happens if we switch to SELL-C-sigma matrix format.\n",
    "* Try to increase C value (maximum possible value is 256) and observe what hapens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a56ac-3a4e-4bed-92b5-148b2d3f0276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"USE_CPU\"]=\"False\"\n",
    "rel_res_in_CG, rel_err, iter, t_pre, t_soln, t_CG = pcg('Laplace200x200x200', 200,  mat_fmt='SELL-8-1', print_perf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3c596-d784-41e8-b2f3-758be2ad3538",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preconditioner and its effects\n",
    "* Now we will experiment with polynomial preconditioner.\n",
    "* Let us stick with the CPU from now on.\n",
    "* We will run the solver till the residual reaches 1e-2. Note: The entire run may take two minutes.\n",
    "* Observe what happens as the degree of polynomial increases.\n",
    "* How does it effect the CG iterations? How about time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe999517-0fc0-4423-adcf-bcff4dbd7d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "degrees=[]\n",
    "iters=[]\n",
    "times=[]\n",
    "plt.subplots(1,3, figsize=(14,6))\n",
    "\n",
    "os.environ[\"USE_CPU\"]=\"True\"\n",
    "plt.subplot(1, 3, 1)\n",
    "for deg in [0,1,2,3]:\n",
    "    rel_res_in_CG, rel_err, iter, t_pre, t_soln, t_CG = pcg('Laplace200x200x200', 10000, poly_k=deg, tol=1e-12)\n",
    "    degrees.append(deg)\n",
    "    iters.append(iter)\n",
    "    times.append(t_CG)\n",
    "    plt.plot(rel_err, label=\"degree=\"+str(deg))\n",
    "\n",
    "    \n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"Iterations to convergence\")\n",
    "plt.plot(degrees, iters)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"Time to convergence\")\n",
    "plt.plot(degrees, times)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ed3b2-4a17-43ad-9029-38f7d88ba1f1",
   "metadata": {},
   "source": [
    "## Cache blocking using RACE\n",
    "* We have seen RACE can allow us to cache block across multiple iterations of MPK solver.\n",
    "* Let us experiment with the efficacy of this method.\n",
    "* Try playing with the following knobs:\n",
    "    * use_RACE: True or False to switch on or off RACE.\n",
    "    * poly_k: The degree of polynomial.\n",
    "    * cache_size: The cache size for which RACE will perform cache blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cad43-cd1f-45a1-ab58-289306ab065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"USE_CPU\"]=\"True\"\n",
    "rel_res_in_CG, rel_err, iter, t_pre, t_soln, t_CG = pcg('Laplace200x200x200', 50, poly_k=2, tol=1e-3, use_RACE=True, cache_size=60, print_perf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832cce9-5919-4106-bf2c-841fbf3eac01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Does RACE impprove the time to solution for polynomial preconditioner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581de5ba-331f-42ec-8df9-3674b7b93039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "degrees=[]\n",
    "iters=[]\n",
    "times=[]\n",
    "plt.subplots(1,3, figsize=(14,6))\n",
    "\n",
    "os.environ[\"USE_CPU\"]=\"True\"\n",
    "plt.subplot(1, 3, 1)\n",
    "for deg in [0,1,2,3]:\n",
    "    rel_res_in_CG, rel_err, iter, t_pre, t_soln, t_CG = pcg('Laplace200x200x200', 10000, poly_k=deg, tol=1e-12, use_RACE=True, cache_size=60)\n",
    "    degrees.append(deg)\n",
    "    iters.append(iter)\n",
    "    times.append(t_CG)\n",
    "    plt.plot(rel_err, label=\"degree=\"+str(deg))\n",
    "\n",
    "    \n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"Iterations to convergence\")\n",
    "plt.plot(degrees, iters)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.xlabel(\"Polynomial degree\")\n",
    "plt.ylabel(\"Time to convergence\")\n",
    "plt.plot(degrees, times)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
